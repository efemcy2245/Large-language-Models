{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 01: Introduction to Deep Learning Models, and their Training, Fine-Tuning, and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- basic functionality of PyTorch, focusing on key operations such as data loading, data transformations, and using GPUs for acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, TensorDataset\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors\n",
    "- Tensors in PyTorch Tensors are the primary data structure in PyTorch. They are similar to NumPy arrays but have added functionality that supports GPU acceleration and automatic differentiation (autograd)\n",
    "\n",
    "Automatic differentiation in PyTorch is a key feature for calculating gradients automatically in tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n",
      "the tensor shape is torch.Size([3])\n",
      "the tensor type is torch.float32\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([ 1.0 , 2.0 , 3.0 ])\n",
    "b = torch.tensor([ 4.0 , 5.0 , 6.0 ])\n",
    "\n",
    "c = a + b     ### addition element-wise\n",
    "print(c) \n",
    "\n",
    "print(f\"the tensor shape is {c.shape}\")\n",
    "print(f\"the tensor type is {c.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "float32 (single precision) data type. NumPy, instead, defaults to float64 (double precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for matrix multiplication (float64): 1.7044s\n",
      "Time for matrix multiplication (float32): 0.7965s\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "mat_size = 1000\n",
    "\n",
    "M1_64 = torch.randn(mat_size, mat_size, dtype=torch.float64)   ### here we have a tensor of double precision float64\n",
    "M2_64 = torch.randn(mat_size, mat_size, dtype=torch.float64)\n",
    "\n",
    "M1_32 = torch.randn(mat_size, mat_size)                        ### here we have a tensor of single precision float32\n",
    "M2_32 = torch.randn(mat_size, mat_size)\n",
    "\n",
    "t64 = timeit(lambda: M1_64 @ M2_64, number=100)                # we use the lambda function tu compute 100 times matrices product      \n",
    "t32 = timeit(lambda: M1_32 @ M2_32, number=100)\n",
    "\n",
    "print(f\"Time for matrix multiplication (float64): {t64:.4f}s\")\n",
    "print(f\"Time for matrix multiplication (float32): {t32:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if is strictly needed you can change the type of array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "c = c.to(torch.float64) # or,\n",
    "print(type(c)) \n",
    "c = c.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: A simple neural network\n",
    "\n",
    "-univariate linear model is one of the most basic forms of machine learning models and is defined by the equation y = wx + b\n",
    "\n",
    "Model Definition: SimpleLinearModel\n",
    "The SimpleLinearModel class is a subclass of nn.Module, which is the base class for all neural network modules in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SimpleLinearModel class is structured as follows:\n",
    "\n",
    "__init__(self, input_size, output_size):\n",
    "\n",
    "This is the constructor method where the linear layer is defined. The input_size and output_size parameters specify the dimensions of the input and output features, respectively. In this exercise, both the input and output sizes are set to 1, indicating a single feature input and a single prediction output.\n",
    "forward(self, x):\n",
    "\n",
    "This method defines the forward pass of the model, where the input x is passed through the linear layer. The forward pass computes the output by applying the linear transformation described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple linear model\n",
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleLinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleLinearModel(\n",
      "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleLinearModel(1, 1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using torch.device for GPU Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is set to: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"The device is set to: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that these tensors have the requires_grad attribute set to True. This attribute is used by PyTorch to determine which tensors should have their gradients computed during the backward pass (i.e., which tensors are learnable parameters). This is used by PyTorch to keep track of the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Parameter containing:\n",
      "tensor([[0.6712]], requires_grad=True)\n",
      "Bias Parameter containing:\n",
      "tensor([-0.4391], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Weight\", model.linear.weight)\n",
    "print(\"Bias\", model.linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criterion and Optimizer\n",
    "\n",
    "-The criterion, also known as the loss function, is a measure of how well the model's predictions match the actual target values. During training, the loss function evaluates the difference between the predicted outputs and the true labels, quantifying the error of the model. The goal of training is to minimize this error, thereby improving the model's accuracy.\n",
    "\n",
    "-Cross Entropy: Used for multi-class classification problems, like our CIFAR-10 and CIFAR-100 tasks. We typically use PyTorch's CrossEntropyLoss, which takes as input the predicted logits (not the probabilities, so unnormalized probabilities that have not been passed through a softmax) is applied) and the ground truths. Alternatively, we could combine LogSoftmax and NLLLoss (Negative Log Likelihood Loss) together, or applying the softmax ourselves and then using a Negative Log Likelihood function. However, for numerical reasons, we generally prefer using the CrossEntropyLoss class directly.\n",
    "\n",
    "-Mean Squared Error (MSE): Typically used for regression tasks, where the model predicts continuous values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer\n",
    "The optimizer is an algorithm or method used to adjust the model's weights to minimize the loss function. It updates the model parameters (weights and biases) based on the gradients computed during backpropagation. The optimizer aims to find the optimal set of parameters that reduce the loss, improving the model’s performance on the training data.\n",
    "\n",
    "Some common optimizers include:\n",
    "\n",
    "-Stochastic Gradient Descent (SGD): A basic optimizer that updates the model parameters using a small, randomly selected subset of data (mini-batch) instead of the entire dataset. It’s useful for handling large datasets and reducing computational cost.\n",
    "\n",
    "-Adam: A more advanced optimizer that combines the benefits of two other extensions of SGD, Adaptive Gradient Algorithm (AdaGrad) and Root Mean Square Propagation (RMSProp). It adjusts the learning rate for each parameter dynamically, making it well-suited for complex tasks with sparse gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset (for simplicity, we use a small synthetic dataset)\n",
    "# X is the input features, y is the target labels\n",
    "\n",
    "n_pts = 2048\n",
    "# TODO: Generate a random dataset containing n_pts samples\n",
    "# Notes:\n",
    "# - The input features X should be a tensor of shape (n_pts, 1)\n",
    "# - you can generate the X's randomly (e.g. using torch.rand to sample uniformly from [0,1], or torch.randn to sample from a normal distribution)\n",
    "# - The target labels y should be a linear function of X with some noise added, y = w*x + b + gaussian noise\n",
    "\n",
    "# In this solution we are using normally distributed inputs. It is \n",
    "# well-known that 0-centered inputs help speed up the learning process.\n",
    "# You can try using uniformly distributed inputs, or adding an offset to\n",
    "# all points and see the difference in learning speed (weight/bias\n",
    "# plots shown afterwards)\n",
    "X = torch.randn(n_pts, 1)      ### shape is [ 2048 , 1 ]\n",
    "y = 5 * X + 3 + 0.1 * torch.randn(n_pts, 1) # adding gaussian noise  ### shape is [ 2048 , 1 ]\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(X, y)\n",
    "trainloader = DataLoader(dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 26.0355\n",
      "Epoch [2/50], Loss: 19.0162\n",
      "Epoch [3/50], Loss: 13.8880\n",
      "Epoch [4/50], Loss: 10.1432\n",
      "Epoch [5/50], Loss: 7.4104\n",
      "Epoch [6/50], Loss: 5.4142\n",
      "Epoch [7/50], Loss: 3.9559\n",
      "Epoch [8/50], Loss: 2.8913\n",
      "Epoch [9/50], Loss: 2.1141\n",
      "Epoch [10/50], Loss: 1.5463\n",
      "Epoch [11/50], Loss: 1.1320\n",
      "Epoch [12/50], Loss: 0.8294\n",
      "Epoch [13/50], Loss: 0.6085\n",
      "Epoch [14/50], Loss: 0.4471\n",
      "Epoch [15/50], Loss: 0.3293\n",
      "Epoch [16/50], Loss: 0.2432\n",
      "Epoch [17/50], Loss: 0.1804\n",
      "Epoch [18/50], Loss: 0.1345\n",
      "Epoch [19/50], Loss: 0.1010\n",
      "Epoch [20/50], Loss: 0.0765\n",
      "Epoch [21/50], Loss: 0.0587\n",
      "Epoch [22/50], Loss: 0.0456\n",
      "Epoch [23/50], Loss: 0.0361\n",
      "Epoch [24/50], Loss: 0.0291\n",
      "Epoch [25/50], Loss: 0.0241\n",
      "Epoch [26/50], Loss: 0.0203\n",
      "Epoch [27/50], Loss: 0.0176\n",
      "Epoch [28/50], Loss: 0.0157\n",
      "Epoch [29/50], Loss: 0.0142\n",
      "Epoch [30/50], Loss: 0.0132\n",
      "Epoch [31/50], Loss: 0.0124\n",
      "Epoch [32/50], Loss: 0.0118\n",
      "Epoch [33/50], Loss: 0.0114\n",
      "Epoch [34/50], Loss: 0.0111\n",
      "Epoch [35/50], Loss: 0.0109\n",
      "Epoch [36/50], Loss: 0.0107\n",
      "Epoch [37/50], Loss: 0.0106\n",
      "Epoch [38/50], Loss: 0.0105\n",
      "Epoch [39/50], Loss: 0.0105\n",
      "Epoch [40/50], Loss: 0.0104\n",
      "Epoch [41/50], Loss: 0.0104\n",
      "Epoch [42/50], Loss: 0.0104\n",
      "Epoch [43/50], Loss: 0.0104\n",
      "Epoch [44/50], Loss: 0.0104\n",
      "Epoch [45/50], Loss: 0.0103\n",
      "Epoch [46/50], Loss: 0.0103\n",
      "Epoch [47/50], Loss: 0.0103\n",
      "Epoch [48/50], Loss: 0.0103\n",
      "Epoch [49/50], Loss: 0.0103\n",
      "Epoch [50/50], Loss: 0.0103\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "# TODO: keep track of the loss computed at each step, \n",
    "# the current value for the weight of the linear layer,\n",
    "# and the current bias value for the linear layer.\n",
    "# Note: store the values in the lists losses, weights, biases\n",
    "losses = []\n",
    "weights = []\n",
    "biases = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save the loss, weight, and bias\n",
    "        losses.append(loss.item())\n",
    "        weights.append(model.linear.weight.item())\n",
    "        biases.append(model.linear.bias.item())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[0].set_xlabel(\"Steps\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].grid()\n",
    "\n",
    "ax[1].plot(weights)\n",
    "ax[1].set_title(\"Weight\")\n",
    "ax[1].set_xlabel(\"Steps\")\n",
    "ax[1].set_ylabel(\"Weight\")\n",
    "ax[1].grid()\n",
    "\n",
    "ax[2].plot(biases)\n",
    "ax[2].set_title(\"Bias\")\n",
    "ax[2].set_xlabel(\"Steps\")\n",
    "ax[2].set_ylabel(\"Bias\")\n",
    "ax[2].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned weights: tensor([[4.9978]])\n",
      "Learned biases: tensor([2.9996])\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the learned weights and biases\n",
    "weights = model.linear.weight.data\n",
    "biases = model.linear.bias.data\n",
    "\n",
    "print(f'Learned weights: {weights}')\n",
    "print(f'Learned biases: {biases}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2: First Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will explore the concept of transfer learning by training a model on the CIFAR-10 dataset and then adapting it to a different dataset, CIFAR-100\n",
    "\n",
    "This approach is especially useful in fields like Natural Language Processing (NLP), where training a model from scratch requires immense computational resources and vast amounts of data. Instead, pre-trained models are often used as backbones, and only the final classification head is fine-tuned for specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 and CIFAR-100 datasets are both standard datasets in computer vision. They contain 32x32 color images, but while CIFAR-10 has 10 classes, CIFAR-100 has 100 classes, making it a more challenging task.\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "Train a model from scratch on CIFAR-10 and evaluate its performance.\n",
    "\n",
    "Compare the performance on CIFAR-10 of two models:\n",
    "\n",
    "-The model trained from scratch from point 1.\n",
    "\n",
    "-A model pre-trained on ImageNet (another dataset of images) and then fine-tuned on CIFAR-10.\n",
    "\n",
    "-Modify the classification head to adapt the model for CIFAR-100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the CIFAR-10 Dataset and Creating a DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply a simple transformation to the images, which start out as PIL images (PIL is a famous Python libraries that handles images), \n",
    "to convert them into PyTorch tensors. We do this using the transforms.ToTensor() transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"~/data\" # Change this to the directory where you want to download the dataset\n",
    "# Download CIFAR-10 dataset and apply the transformations\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=dataset_dir, train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Create a DataLoader\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "# Get a batch of data to verify that everything is working\n",
    "# dataiter = iter(trainloader)\n",
    "images, labels = next(iter(trainloader)) #dataiter.next()\n",
    "\n",
    "print(f\"Batch of images shape: {images.shape}\")\n",
    "print(f\"Batch of labels shape: {labels.shape}\")\n",
    "print(f\"Possible classes: {', '.join(trainset.classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(8,8, figsize=(8,8))\n",
    "plt.rcParams.update({'axes.titlesize': 'small'})\n",
    "plt.tight_layout()\n",
    "# remove vertical space\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.1)\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        # note that we need to change the order of the dimensions.\n",
    "        # Torch prepare the images to be (C, H, W),\n",
    "        # But matplotlib expects (H, W, C)\n",
    "        # (H = height of the image, W = width of the image, C = number of color channels)\n",
    "        ax[i,j].imshow(images[i*8 + j].permute(1,2,0))\n",
    "        ax[i,j].set_title(trainset.classes[labels[i*8 + j]])\n",
    "        ax[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformations\n",
    "\n",
    "Transformations involve modifying the inputs (e.g., images) in the dataset to make the model more robust to variations in input data and prevent overfitting\n",
    "\n",
    "It's important to note that the transformations applied to the training data differ from those applied to the validation data\n",
    "\n",
    "Training Transformations\n",
    "\n",
    "Training transformations are designed to augment the dataset, effectively increasing the diversity of the input images seen by the model during training. This helps improve the model's ability to generalize to unseen data. Common training transformations include:\n",
    "\n",
    "Random Crop: Randomly crops a given portion of an image. This helps the model become invariant to the position of objects within the image.\n",
    "\n",
    "Random Horizontal Flip: Randomly flips an image horizontally. This technique ensures that the model learns features regardless of the orientation of objects.\n",
    "\n",
    "Normalization: Adjusts the pixel values to have a mean of 0 and a standard deviation of 1. Normalization helps speed up training and can lead to better model performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Transformations\n",
    "Validation transformations, on the other hand, are intended to provide a consistent evaluation of model performance by ensuring the input data is in a standardized format. Typically, validation transformations include:\n",
    "\n",
    "Normalization: Similar to training, normalization is applied to adjust the pixel values to have a mean of 0 and a standard deviation of 1. This ensures that the distribution of values in the validation samples is the same one used in the training samples (since the model already learned to expect that distribution of values).\n",
    "\n",
    "So, the key difference is that training transformations often include random augmentations (such as cropping and flipping) to introduce variability, whereas validation transformations are more standardized and deterministic to provide a stable basis for evaluating the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: find the mean value and the standard deviation of the images in the dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Note:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# - The images are available in trainset.data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# - Scale the images to the [0,1] range before proceeding\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# - Compute a different mean and standard deviation for each color channel\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m images_mean \u001b[38;5;241m=\u001b[39m \u001b[43mtrainset\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m      7\u001b[0m images_std \u001b[38;5;241m=\u001b[39m trainset\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mstd(axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m      9\u001b[0m images_mean, images_std\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: find the mean value and the standard deviation of the images in the dataset\n",
    "# Note:\n",
    "# - The images are available in trainset.data\n",
    "# - Scale the images to the [0,1] range before proceeding\n",
    "# - Compute a different mean and standard deviation for each color channel\n",
    "images_mean = trainset.data.mean(axis=(0,1,2)) / 255\n",
    "images_std = trainset.data.std(axis=(0,1,2)) / 255\n",
    "\n",
    "images_mean, images_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the transformations, we can pass the transformation objects to the transform argument of the CIFAR10 class. This way, the transformations are automatically applied when loading the data using the DataLoader.\n",
    "\n",
    "Let's see what the same image looks like after applying these transformations.\n",
    "\n",
    "Note that we are creating a different transformation, without the normalization step (& conversion to tensor), for the visualization. This occurs because the normalization step would make the image look strange, as it would change the pixel values to have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # note the padding_mode policy: this implies that the \"missing\" pixels\n",
    "    # will be reflected from the border pixels\n",
    "    # (more info in the documentation => https://pytorch.org/vision/main/generated/torchvision.transforms.RandomCrop.html)\n",
    "    transforms.RandomCrop(32, padding_mode='reflect', padding=5)\n",
    "])\n",
    "\n",
    "im = transforms.ToPILImage()(images[10])\n",
    "n_transforms = 9\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize=(4,4))\n",
    "# TODO: Visualize the original image ,then apply different transformations to it\n",
    "# Note: each time you apply the viz_transform transformation, a random transformation will be applied to the image\n",
    "for i in range(n_transforms):\n",
    "    if i == 0: # The first image is the original one\n",
    "        ax[i//3,i%3].imshow(im)\n",
    "    else: # The rest are the transformed images\n",
    "        ax[i//3,i%3].imshow(viz_transform(im))\n",
    "    ax[i//3,i%3].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra stuff!\n",
    "\n",
    "Other transformations are already supported in PyTorch, such as:\n",
    "\n",
    "RandomRotation: Rotates the image by a random angle.\n",
    "RandomResizedCrop: Crops the image to a random size and aspect ratio, then resizes it to the specified size.\n",
    "ColorJitter: Randomly changes the brightness, contrast, saturation, and hue of an image.\n",
    "RandomAffine: Applies a random affine transformation to the image.\n",
    "RandomPerspective: Applies a random perspective transformation to the image.\n",
    "RandomErasing: Randomly selects a rectangle region in an image and erases its pixels.\n",
    "You can find out more about those transformations in the official documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2.0 Building and Training a Simple Neural Network for CIFAR-10 Classification\n",
    "In this exercise, we extend our exploration of machine learning models by constructing a simple neural network to classify images from the CIFAR-10 dataset using PyTorch. Unlike the linear model, which is limited to learning linear relationships between features, this neural network introduces multiple layers and non-linear activation functions, allowing it to capture more complex patterns in the data.\n",
    "\n",
    "A neural network consists of interconnected layers of nodes, or neurons, where each layer applies a linear transformation to its input, followed by a non-linear activation. The architecture we will implement includes:\n",
    "\n",
    "Input Layer: Accepts the flattened input image, with each pixel value as a feature.\n",
    "Hidden Layers: Two fully connected layers that transform the input into higher-level features using linear transformations and ReLU activation functions.\n",
    "Output Layer: A final fully connected layer that maps the transformed features to the 10 output classes of the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a more complex neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # TODO: Define the linear layers for the model\n",
    "        # Notes:\n",
    "        # - Each layer requires specifying the number of input and output features\n",
    "        # - The first layer takes as input a flattened image (32x32x3) and should produce 512 features\n",
    "        #   (i.e., it encodes the image into a 512-dimensional space)\n",
    "        # - The second layer should produce 256 features\n",
    "        # - The output layer should produce 10 features (these will be the logits)\n",
    "\n",
    "        # number of input features: 32*32*3 (image size)\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 512)  # Input layer to first hidden layer\n",
    "        self.fc2 = nn.Linear(512, 256)  # First hidden layer to second hidden layer\n",
    "        self.fc3 = nn.Linear(256, 10)   # Second hidden layer to output layer\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: implement the forward pass\n",
    "        # Notes:\n",
    "        # - first step: flatten the input (preserve the batch size, flatten the rest)\n",
    "        # - apply the first linear layer with ReLU activation\n",
    "        # - apply the second linear layer with ReLU activation\n",
    "        # - apply the output layer (no activation needed for the output layer)\n",
    "\n",
    "        # Flatten the input\n",
    "        x = x.view(-1, 32 * 32 * 3)\n",
    "        # Apply layers with ReLU activation\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # Output layer (no activation needed for the output layer)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for the training and test datasets\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding_mode='reflect', padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "batch_size = 1024\n",
    "trainset = torchvision.datasets.CIFAR10(root=dataset_dir, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=dataset_dir, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleNN()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_model(model, testloader):\n",
    "    model.eval() # NOTE: required to set the model to evaluation mode (some layers may behave differently during training and evaluation)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # NOTE: we disable gradient tracking for validation, to save memory!\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy of the network on the test images: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # TODO: let's implement the training loop for the model\n",
    "        # Notes:\n",
    "        # - First, zero the parameter gradients\n",
    "        # - Next, get the model's predictions\n",
    "        # - Compute the loss\n",
    "        # - Perform backpropagation (i.e. compute all gradients)\n",
    "        # - Finally, update the model's parameters\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra stuff!\n",
    "\n",
    "Now the model has a bunch more weights and biases (parameters) to learn. Unlike before, we don't know exactly what the \"right\" values should be. Pick a few random parameters from the various layers and keep track of how their values change over time!\n",
    "\n",
    "(Note: make sure to extract the values from the tensors using the .item() method, as shown in the previous example, otherwise the computation graph will keep track of the values and you will run out of memory!)\n",
    "\n",
    "Let's check the model's performance on the validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(losses)\n",
    "ax.set_xlabel(\"Steps\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra stuff!\n",
    "\n",
    "While this model performs better than random guess (~10% accuracy), it still far from perfect. Compute the confusion matrix on the validation set. Which classes does the model classify better? Which classes does it struggle with? Which classes are most often confused with each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Train a Model on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root=dataset_dir, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=dataset_dir, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=512, shuffle=False)\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "# Load a pre-trained model (ResNet18)\n",
    "model = models.resnet18(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)  # CIFAR-10 has 10 classes\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "val_model(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(losses)\n",
    "ax.set_xlabel(\"Steps\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Train a Model on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root=dataset_dir, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=dataset_dir, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=512, shuffle=False)\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "# Load a pre-trained model (ResNet18)\n",
    "model = models.resnet18(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)  # CIFAR-10 has 10 classes\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "val_model(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(losses)\n",
    "ax.set_xlabel(\"Steps\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load and Train a pre-trained Model on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load a pre-trained model (ResNet18)\n",
    "# Notes:\n",
    "# - To load a pre-trained model, call models.resnet18 and set the weights argument to 'DEFAULT'\n",
    "# - The model has a fully connected layer at the end (called `fc`) that needs to be replaced with a new one of the appropriate size\n",
    "# - To get the number of input features for the new layer, you can access the in_features attribute of the original fc layer\n",
    "\n",
    "pretrained_model = models.resnet18(weights=\"DEFAULT\")\n",
    "pretrained_model.fc = nn.Linear(model.fc.in_features, 10)  # CIFAR-10 has 10 classes\n",
    "pretrained_model = pretrained_model.to(device) # move the model (all layers, even new ones) to the device\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(pretrained_model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = pretrained_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model(pretrained_model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(losses)\n",
    "ax.set_xlabel(\"Steps\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the Classification Head of an already trained Model on CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will modify the classification head of a pre-trained model on CIFAR-10 to adapt it to the CIFAR-100 dataset. This process involves changing the output layer of the model to accommodate the 100 classes in CIFAR-100 instead of the 10 classes in CIFAR-10. By changing the classification head, we can repurpose the pre-trained model to perform well on a different task with minimal additional training.\n",
    "\n",
    "We do this by employing a common technique in transfer learning, known as layer freezing, to adapt a pre-trained model to a new task with minimal training time. Layer freezing involves setting the requires_grad attribute of specific model parameters to False, effectively preventing them from being updated during the backpropagation process. By freezing all layers except for the final classification head, we retain the knowledge encoded in the pre-trained layers while allowing the model to learn task-specific features through the unfrozen layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-100 dataset\n",
    "trainset_cifar100 = torchvision.datasets.CIFAR100(root=dataset_dir, train=True, download=True, transform=transform_train)\n",
    "trainloader_cifar100 = torch.utils.data.DataLoader(trainset_cifar100, batch_size=100, shuffle=True)\n",
    "\n",
    "testset_cifar100 = torchvision.datasets.CIFAR100(root=dataset_dir, train=False, download=True, transform=transform_test)\n",
    "testloader_cifar100 = torch.utils.data.DataLoader(testset_cifar100, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the classification head for CIFAR-100 (100 classes)\n",
    "\n",
    "model = pretrained_model\n",
    "model.fc = nn.Linear(model.fc.in_features, 100)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we freeze all layers except for the newly modified classification head by iterating through the model's parameters and setting requires_grad = False for each. Subsequently, we explicitly enable gradient computation (requires_grad = True) for the parameters in the classification head. This approach allows us to fine-tune the output layer to classify the 100 classes in the CIFAR-100 dataset while preserving the general features learned from the CIFAR-10 dataset, ensuring that the model adapts effectively to the new task using the information already learned from the previous task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the classification head\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# TODO: Unfreeze the classification head\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader_cifar100:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader_cifar100):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model(model, testloader_cifar100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(losses)\n",
    "ax.set_xlabel(\"Steps\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Define tensors with requires_grad=True to track operations\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "c = torch.tensor(4.0, requires_grad=True)\n",
    "\n",
    "# Define a function involving these tensors\n",
    "y = (a*b*c+c)*c + b\n",
    "\n",
    "# Visualize the computational graph\n",
    "make_dot(y, params={\"a\": a, \"b\": b, \"c\": c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "import torch\n",
    "\n",
    "# TODO: define the tensors and compute the loss\n",
    "# Define theta1, theta2, x, and y as tensors, then compute the loss\n",
    "# Notes:\n",
    "# - set theta1 = 2.0, theta2 = 3.0, x = 1.0, y = 3.0\n",
    "# - the loss is defined as (theta1 * theta2 * x - y)^2\n",
    "# - all the tensors should be specified to require gradients\n",
    "theta1 = torch.tensor(2.0, requires_grad=True)\n",
    "theta2 = torch.tensor(3.0, requires_grad=True)\n",
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "loss = (theta1 * theta2 * x - y)**2\n",
    "\n",
    "# TODO: Visualize the computational graph\n",
    "make_dot(loss, params={\"theta1\": theta1, \"theta2\": theta2, \"x\": x, \"y\": y})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
